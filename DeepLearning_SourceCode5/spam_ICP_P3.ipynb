{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Spam.csv', encoding ='latin-1')\n",
    "# Keeping only the neccessary columns\n",
    "data.info()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v2'] = data['v2'].apply(lambda x: x.lower())\n",
    "data['v2'] = data['v2'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['v2'].values)\n",
    "X = tokenizer.texts_to_sequences(data['v2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "def createmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "integer_encoded = labelencoder.fit_transform(data['v1'])\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
    "print(labelencoder.classes_)\n",
    "print(labelencoder.transform(labelencoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 61s 325ms/step - loss: 0.1598 - accuracy: 0.9474\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0669 - accuracy: 0.9826\n",
      "187/187 [==============================] - 58s 312ms/step - loss: 0.1626 - accuracy: 0.9474\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0639 - accuracy: 0.9826\n",
      "187/187 [==============================] - 59s 317ms/step - loss: 0.1548 - accuracy: 0.9471\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0769 - accuracy: 0.9746\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.1504 - accuracy: 0.9474\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0682 - accuracy: 0.9786\n",
      "187/187 [==============================] - 58s 312ms/step - loss: 0.1490 - accuracy: 0.9521\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0585 - accuracy: 0.9759\n",
      "Epoch 1/2\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.1416 - accuracy: 0.9531\n",
      "Epoch 2/2\n",
      "187/187 [==============================] - 61s 326ms/step - loss: 0.0351 - accuracy: 0.9883\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0598 - accuracy: 0.9853\n",
      "Epoch 1/2\n",
      "187/187 [==============================] - 59s 317ms/step - loss: 0.1421 - accuracy: 0.9521\n",
      "Epoch 2/2\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.0418 - accuracy: 0.9856\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0446 - accuracy: 0.9893\n",
      "Epoch 1/2\n",
      "187/187 [==============================] - 59s 313ms/step - loss: 0.1550 - accuracy: 0.9464\n",
      "Epoch 2/2\n",
      "187/187 [==============================] - 88s 472ms/step - loss: 0.0350 - accuracy: 0.9886\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0776 - accuracy: 0.9772\n",
      "Epoch 1/2\n",
      "187/187 [==============================] - 1731s 9s/step - loss: 0.1511 - accuracy: 0.9505\n",
      "Epoch 2/2\n",
      "187/187 [==============================] - 108s 576ms/step - loss: 0.0351 - accuracy: 0.9900\n",
      "47/47 [==============================] - 4s 77ms/step - loss: 0.0690 - accuracy: 0.9799\n",
      "Epoch 1/2\n",
      "187/187 [==============================] - 113s 603ms/step - loss: 0.1506 - accuracy: 0.9488\n",
      "Epoch 2/2\n",
      "187/187 [==============================] - 113s 605ms/step - loss: 0.0373 - accuracy: 0.9890\n",
      "47/47 [==============================] - 3s 61ms/step - loss: 0.0610 - accuracy: 0.9786\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 111s 596ms/step - loss: 0.1480 - accuracy: 0.9491\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 100s 532ms/step - loss: 0.0349 - accuracy: 0.9889\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 98s 523ms/step - loss: 0.0196 - accuracy: 0.9946\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 0.0634 - accuracy: 0.9906\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 104s 557ms/step - loss: 0.1543 - accuracy: 0.9461\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 97s 518ms/step - loss: 0.0411 - accuracy: 0.9866\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 89s 477ms/step - loss: 0.0162 - accuracy: 0.9956\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 0.0502 - accuracy: 0.9880\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 90s 483ms/step - loss: 0.1410 - accuracy: 0.9531\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 90s 483ms/step - loss: 0.0369 - accuracy: 0.9903\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 90s 482ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 0.0717 - accuracy: 0.9813\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 83s 444ms/step - loss: 0.1514 - accuracy: 0.9494\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 74s 395ms/step - loss: 0.0412 - accuracy: 0.9883\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 68s 362ms/step - loss: 0.0172 - accuracy: 0.9946\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 0.0689 - accuracy: 0.9812\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 59s 313ms/step - loss: 0.1601 - accuracy: 0.9505\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 84s 448ms/step - loss: 0.0399 - accuracy: 0.9886\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 83s 442ms/step - loss: 0.0137 - accuracy: 0.9960\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 0.0697 - accuracy: 0.9718\n",
      "94/94 [==============================] - 46s 489ms/step - loss: 0.1787 - accuracy: 0.9414\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.0655 - accuracy: 0.9799\n",
      "94/94 [==============================] - 50s 534ms/step - loss: 0.1881 - accuracy: 0.9354\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 0.0573 - accuracy: 0.9880\n",
      "94/94 [==============================] - 47s 496ms/step - loss: 0.1960 - accuracy: 0.9347\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0911 - accuracy: 0.9759\n",
      "94/94 [==============================] - 47s 499ms/step - loss: 0.1787 - accuracy: 0.9414\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.0645 - accuracy: 0.9812\n",
      "94/94 [==============================] - 50s 537ms/step - loss: 0.1923 - accuracy: 0.9351\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.0570 - accuracy: 0.9772\n",
      "Epoch 1/2\n",
      "94/94 [==============================] - 45s 478ms/step - loss: 0.1754 - accuracy: 0.9444\n",
      "Epoch 2/2\n",
      "94/94 [==============================] - 46s 486ms/step - loss: 0.0449 - accuracy: 0.9856\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.0634 - accuracy: 0.9839\n",
      "Epoch 1/2\n",
      "94/94 [==============================] - 45s 482ms/step - loss: 0.1867 - accuracy: 0.9411\n",
      "Epoch 2/2\n",
      "94/94 [==============================] - 47s 503ms/step - loss: 0.0411 - accuracy: 0.9863\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.0479 - accuracy: 0.9853\n",
      "Epoch 1/2\n",
      "94/94 [==============================] - 45s 478ms/step - loss: 0.2076 - accuracy: 0.9270\n",
      "Epoch 2/2\n",
      "94/94 [==============================] - 45s 478ms/step - loss: 0.0395 - accuracy: 0.9883\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.0688 - accuracy: 0.9746\n",
      "Epoch 1/2\n",
      "94/94 [==============================] - 50s 534ms/step - loss: 0.1890 - accuracy: 0.9391\n",
      "Epoch 2/2\n",
      "94/94 [==============================] - 39s 419ms/step - loss: 0.0423 - accuracy: 0.9876\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.0600 - accuracy: 0.9812\n",
      "Epoch 1/2\n",
      "94/94 [==============================] - 39s 412ms/step - loss: 0.2199 - accuracy: 0.9220\n",
      "Epoch 2/2\n",
      "94/94 [==============================] - 38s 408ms/step - loss: 0.0454 - accuracy: 0.9879\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.0589 - accuracy: 0.9812\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - 39s 416ms/step - loss: 0.1999 - accuracy: 0.9357\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 38s 407ms/step - loss: 0.0415 - accuracy: 0.9859\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 38s 402ms/step - loss: 0.0177 - accuracy: 0.9933\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0842 - accuracy: 0.9759\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - 40s 426ms/step - loss: 0.2057 - accuracy: 0.9293\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 38s 401ms/step - loss: 0.0465 - accuracy: 0.9849\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 38s 401ms/step - loss: 0.0219 - accuracy: 0.9936\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0545 - accuracy: 0.9853\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - 39s 410ms/step - loss: 0.1828 - accuracy: 0.9374\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 38s 405ms/step - loss: 0.0422 - accuracy: 0.9859\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 39s 411ms/step - loss: 0.0192 - accuracy: 0.9960\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0837 - accuracy: 0.9746\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - 38s 409ms/step - loss: 0.1843 - accuracy: 0.9404\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 39s 413ms/step - loss: 0.0435 - accuracy: 0.9856\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 38s 404ms/step - loss: 0.0232 - accuracy: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0714 - accuracy: 0.9839\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - 38s 409ms/step - loss: 0.1817 - accuracy: 0.9377\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 37s 396ms/step - loss: 0.0416 - accuracy: 0.9883\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 38s 399ms/step - loss: 0.0194 - accuracy: 0.9946\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.0677 - accuracy: 0.9786\n",
      "47/47 [==============================] - 33s 693ms/step - loss: 0.2602 - accuracy: 0.9129\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 0.0835 - accuracy: 0.9772\n",
      "47/47 [==============================] - 32s 680ms/step - loss: 0.2646 - accuracy: 0.9156\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0784 - accuracy: 0.9705\n",
      "47/47 [==============================] - 31s 657ms/step - loss: 0.3051 - accuracy: 0.8928\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1093 - accuracy: 0.9692\n",
      "47/47 [==============================] - 31s 670ms/step - loss: 0.2754 - accuracy: 0.9012\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1110 - accuracy: 0.9625\n",
      "47/47 [==============================] - 32s 674ms/step - loss: 0.3120 - accuracy: 0.8815\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1118 - accuracy: 0.9732\n",
      "Epoch 1/2\n",
      "47/47 [==============================] - 34s 716ms/step - loss: 0.2972 - accuracy: 0.8969\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 31s 664ms/step - loss: 0.0580 - accuracy: 0.9819\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.0731 - accuracy: 0.9799\n",
      "Epoch 1/2\n",
      "47/47 [==============================] - 31s 665ms/step - loss: 0.2749 - accuracy: 0.9089\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 31s 669ms/step - loss: 0.0592 - accuracy: 0.9806\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.0609 - accuracy: 0.9853\n",
      "Epoch 1/2\n",
      "47/47 [==============================] - 33s 695ms/step - loss: 0.2849 - accuracy: 0.9056\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 40s 851ms/step - loss: 0.0536 - accuracy: 0.9849\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.0802 - accuracy: 0.9746\n",
      "Epoch 1/2\n",
      "47/47 [==============================] - 35s 753ms/step - loss: 0.2719 - accuracy: 0.9083\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 51s 1s/step - loss: 0.0565 - accuracy: 0.9839\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0610 - accuracy: 0.9853\n",
      "Epoch 1/2\n",
      "47/47 [==============================] - 48s 1s/step - loss: 0.2735 - accuracy: 0.9022\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 37s 781ms/step - loss: 0.0546 - accuracy: 0.9826\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.0645 - accuracy: 0.9786\n",
      "Epoch 1/3\n",
      "47/47 [==============================] - 31s 654ms/step - loss: 0.2677 - accuracy: 0.9099\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 46s 977ms/step - loss: 0.0548 - accuracy: 0.9839\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 40s 841ms/step - loss: 0.0230 - accuracy: 0.9920\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.0610 - accuracy: 0.9799\n",
      "Epoch 1/3\n",
      "47/47 [==============================] - 41s 869ms/step - loss: 0.2699 - accuracy: 0.9092\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 45s 967ms/step - loss: 0.0624 - accuracy: 0.9812\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 47s 1s/step - loss: 0.0315 - accuracy: 0.9900\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 0.0444 - accuracy: 0.9839\n",
      "Epoch 1/3\n",
      "47/47 [==============================] - 39s 834ms/step - loss: 0.2829 - accuracy: 0.8942\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 36s 775ms/step - loss: 0.0543 - accuracy: 0.9839\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 33s 697ms/step - loss: 0.0245 - accuracy: 0.9923\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.0720 - accuracy: 0.9746\n",
      "Epoch 1/3\n",
      "47/47 [==============================] - 38s 798ms/step - loss: 0.2470 - accuracy: 0.9116\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 41s 876ms/step - loss: 0.0619 - accuracy: 0.9799\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 31s 668ms/step - loss: 0.0271 - accuracy: 0.9916\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.0756 - accuracy: 0.9812\n",
      "Epoch 1/3\n",
      "47/47 [==============================] - 31s 664ms/step - loss: 0.2334 - accuracy: 0.9223\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 30s 647ms/step - loss: 0.0492 - accuracy: 0.9839\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 28s 587ms/step - loss: 0.0231 - accuracy: 0.9940\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.0628 - accuracy: 0.9799\n",
      "Epoch 1/3\n",
      "234/234 [==============================] - 84s 360ms/step - loss: 0.1370 - accuracy: 0.9539\n",
      "Epoch 2/3\n",
      "234/234 [==============================] - 75s 318ms/step - loss: 0.0354 - accuracy: 0.9885\n",
      "Epoch 3/3\n",
      "234/234 [==============================] - 81s 345ms/step - loss: 0.0138 - accuracy: 0.9971\n",
      "Best: 0.982585 using {'batch_size': 16, 'epochs': 3}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "batch_size = [16,32,64]\n",
    "epochs = [1,2,3]\n",
    "model = KerasClassifier(build_fn=createmodel,verbose=1)\n",
    "param_grid= dict(batch_size=batch_size, epochs=epochs)\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result= grid.fit(X_train, Y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "234/234 [==============================] - 78s 332ms/step - loss: 0.1582 - accuracy: 0.9520\n",
      "Epoch 2/3\n",
      "234/234 [==============================] - 84s 357ms/step - loss: 0.0379 - accuracy: 0.9887\n",
      "Epoch 3/3\n",
      "234/234 [==============================] - 77s 328ms/step - loss: 0.0162 - accuracy: 0.9962\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.0744 - accuracy: 0.9821\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_92 (Embedding)     (None, 152, 128)          256000    \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "0.07439438998699188\n",
      "0.9820554852485657\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "best_model = createmodel()\n",
    "best_model.fit(X_train, Y_train, epochs = 3, batch_size=16, verbose = 1)\n",
    "score,acc = best_model.evaluate(X_test,Y_test,verbose=1,batch_size=16)\n",
    "print(best_model.summary())\n",
    "print(score)\n",
    "print(acc)\n",
    "print(best_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"spam_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-9893ee781ee8>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(best_model.predict_classes(X_test[[5],:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
